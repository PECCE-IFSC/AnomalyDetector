{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector de anomalia com LSTM\n",
    "## Import dos módulos necessários para o projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import h5py\n",
    "import pickle\n",
    "import ibmiotf\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import ibmiotf.application\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from queue import Queue\n",
    "from numpy import concatenate\n",
    "from keras.callbacks import Callback\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.models import Sequential, model_from_json\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dos arquivos do repositório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm watsoniotp.*\n",
    "!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.healthy.phase_aligned.pickle\n",
    "!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.broken.phase_aligned.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos arquivos e formatação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy = pickle.load(open('watsoniotp.healthy.phase_aligned.pickle', 'rb'), encoding='latin1')\n",
    "data_broken = pickle.load(open('watsoniotp.broken.phase_aligned.pickle', 'rb'), encoding='latin1')\n",
    "\n",
    "data_healthy = data_healthy.reshape(3000,3)\n",
    "data_broken = data_broken.reshape(3000,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos dados\n",
    "\n",
    "### - Dados Saudáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(data_healthy)\n",
    "ax.set_title('Healthy data')\n",
    "ax.plot(range(0,size), data_healthy[:,0], '-', color='blue', animated = True, linewidth=1, label=\"x\")\n",
    "ax.plot(range(0,size), data_healthy[:,1], '-', color='red', animated = True, linewidth=1, label=\"y\")\n",
    "ax.plot(range(0,size), data_healthy[:,2], '-', color='green', animated = True, linewidth=1, label=\"z\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Dados Avariados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(data_healthy)\n",
    "ax.set_title('Broken data')\n",
    "ax.plot(range(0,size), data_broken[:,0], '-', color='blue', animated = True, linewidth=1, label=\"x\")\n",
    "ax.plot(range(0,size), data_broken[:,1], '-', color='red', animated = True, linewidth=1, label=\"y\")\n",
    "ax.plot(range(0,size), data_broken[:,2], '-', color='green', animated = True, linewidth=1, label=\"z\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - FFT dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy_fft = np.fft.fft(data_healthy)\n",
    "\n",
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(data_healthy_fft)\n",
    "ax.set_title('Healthy FFT')\n",
    "ax.plot(range(0,size), data_healthy_fft[:,0].real, '-', color='blue', animated = True, linewidth=1, label=\"x\")\n",
    "ax.plot(range(0,size), data_healthy_fft[:,1].imag, '-', color='red', animated = True, linewidth=1, label=\"y\")\n",
    "ax.plot(range(0,size), data_healthy_fft[:,2].real, '-', color='green', animated = True, linewidth=1, label=\"z\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broken_fft = np.fft.fft(data_broken)\n",
    "\n",
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(data_healthy_fft)\n",
    "ax.set_title('Broken FFT')\n",
    "ax.plot(range(0,size), data_broken_fft[:,0].real, '-', color='blue', animated = True, linewidth=1, label=\"x\")\n",
    "ax.plot(range(0,size), data_broken_fft[:,1].imag, '-', color='red', animated = True, linewidth=1, label=\"y\")\n",
    "ax.plot(range(0,size), data_broken_fft[:,2].real, '-', color='green', animated = True, linewidth=1, label=\"z\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy_scaled = scaleData(data_healthy)\n",
    "data_broken_scaled = scaleData(data_broken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatação dos dados no formato (300,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "dim = 3\n",
    "samples = 3000\n",
    "data_healthy_scaled_reshaped = data_healthy_scaled\n",
    "data_healthy_scaled_reshaped.shape = (int(samples/timesteps),timesteps,dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerenciamento das perdas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "def handleLoss(loss):\n",
    "        global losses\n",
    "        losses+=[loss]\n",
    "        print(loss)\n",
    "        \n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        handleLoss(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo com Keras e LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(Dense(3))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    data.shape = (300, 10, 3)\n",
    "    model.fit(data, data, epochs=50, batch_size=72, validation_data=(data, data), verbose=1, shuffle=False,\n",
    "              callbacks=[LossHistory()])\n",
    "    data.shape = (3000, 3)\n",
    "\n",
    "def score(data):\n",
    "    data.shape = (300, 10, 3)\n",
    "    yhat = model.predict(data)\n",
    "    yhat.shape = (3000, 3)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"Train with healthy data\"\n",
    "print(\"----------------healthy\")\n",
    "for i in range(20):\n",
    "    \n",
    "    print (f\"{i}\", end = \" \")\n",
    "    train(data_healthy_scaled)\n",
    "    yhat_healthy = score(data_healthy_scaled)\n",
    "    yhat_broken = score(data_broken_scaled)\n",
    "    data_healthy_scaled.shape = (3000, 3)\n",
    "    data_broken_scaled.shape = (3000, 3)\n",
    "    print()\n",
    "\n",
    "\"Train with broken data\"\n",
    "print (\"Broken \")\n",
    "train(data_broken_scaled)\n",
    "yhat_healthy = score(data_healthy_scaled)\n",
    "yhat_broken = score(data_broken_scaled)\n",
    "data_healthy_scaled.shape = (3000, 3)\n",
    "data_broken_scaled.shape = (3000, 3)\n",
    "\n",
    "\"Saves the model\"\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "\n",
    "\"Losses plot\"\n",
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(data_healthy_fft)\n",
    "ax.set_title(\"Losses\")\n",
    "ax.plot(range(0,len(losses)), losses, '-', color='blue', animated = True, linewidth=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "#Load weights\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão com a rede de gerenciamento IOT da IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options = {\"org\": \"rluizn\", \"id\": \"Anoomaly\", \"auth-method\": \"apikey\", \"auth-key\": \"a-rluizn-lllwueo4ze\", \"auth-token\": \"c6thbjGC0hH-I+2cp)\"}\n",
    "client = ibmiotf.application.Client(options)\n",
    "client.connect()\n",
    "\n",
    "q = Queue(7000)\n",
    "\n",
    "def myEventCallback(event):\n",
    "    sample = event.data\n",
    "    point = [sample[\"x\"], sample[\"y\"],sample[\"z\"]]\n",
    "    print(point)\n",
    "    q.put(point)\n",
    "\n",
    "client.deviceEventCallback = myEventCallback\n",
    "# Argumentos: (deviceType, deviceId, eventId, msgFormat)\n",
    "client.subscribeToDeviceEvents(\"0.16.2\", \"lorenz\", \"osc\", \"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Definição do treinamento da rede constantemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def doNN(data):\n",
    "    data_scaled = scaleData(data)\n",
    "    train(data_scaled)\n",
    "    yhat = score(data_scaled)\n",
    "    data_scaled.shape = (3000, 3)\n",
    "\n",
    "# Redefinição do gerenciamento das perdas, com o envio de eventos no iot\n",
    "def handleLoss(loss):\n",
    "        myData={'loss' : str(loss)}\n",
    "        #Argumentos: (deviceType, deviceId, eventId, msgFormat)\n",
    "        client.publishEvent(\"0.16.2\", \"lorenz\", \"status\", \"json\", myData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento os dados em tempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    while not q.empty():\n",
    "        point = q.get()\n",
    "        try:\n",
    "            data\n",
    "            print(data)\n",
    "        except NameError:\n",
    "            print(\"none\")\n",
    "            data = np.array(point)\n",
    "        else:\n",
    "            data = np.append(data,point)\n",
    "            print(f\"Size: {data.size}\")\n",
    "        if data.size>=9000:\n",
    "            data = np.reshape(data,(3000,3))\n",
    "            print(data)\n",
    "            doNN(data)\n",
    "            del data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
